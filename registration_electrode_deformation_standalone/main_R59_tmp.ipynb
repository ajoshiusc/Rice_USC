{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rodent Brain Atlas Registration and Electrode Deformation\n",
    "\n",
    "This notebook demonstrates a complete pipeline for registering rodent brain atlases and performing electrode deformation analysis. The workflow includes:\n",
    "\n",
    "1. **Initial Setup and Data Loading**\n",
    "2. **Rigid Registration** - Center alignment of atlas to subject\n",
    "3. **Affine Registration** - Linear alignment refinement  \n",
    "4. **Non-linear Registration** - Deformable registration for precise anatomical matching\n",
    "5. **Electrode Deformation Analysis** - Modeling tissue deformation around implanted electrodes\n",
    "\n",
    "## Overview\n",
    "\n",
    "This registration pipeline uses the Waxholm Space (WHS) rat brain atlas to register with individual subject brain images, followed by specialized electrode deformation modeling. The process is essential for:\n",
    "\n",
    "- Accurate anatomical labeling of subject brain regions\n",
    "- Understanding tissue displacement due to electrode implantation\n",
    "- Quantifying registration quality through Jacobian determinant analysis\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "The notebook requires the following packages:\n",
    "- `nilearn` - Neuroimaging analysis and visualization\n",
    "- `nibabel` - NIfTI image I/O\n",
    "- `SimpleITK` - Image registration toolkit\n",
    "- `MONAI` - Medical imaging transformations\n",
    "- `numpy` - Numerical computing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Initialize Environment\n",
    "\n",
    "Import all necessary libraries for image processing, registration, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "# All dependencies are now in the current directory\n",
    "import nilearn.image as ni\n",
    "import nibabel as nb\n",
    "from nilearn.plotting import plot_anat, plot_prob_atlas, show, plot_stat_map\n",
    "import SimpleITK as sitk\n",
    "from utils import pad_nifti_image, multires_registration, interpolate_zeros\n",
    "from aligner import Aligner\n",
    "from warp_utils import apply_warp\n",
    "import numpy as np\n",
    "from monai.transforms import LoadImage, EnsureChannelFirst\n",
    "from warper import Warper\n",
    "from nibabel.processing import resample_to_output\n",
    "\n",
    "\n",
    "\n",
    "# %matplotlib notebook\n",
    "# import gui\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure File Paths\n",
    "\n",
    "Define all input and output file paths for the registration pipeline. \n",
    "\n",
    "**Input Files:**\n",
    "- Subject BSE T2 image\n",
    "- Atlas BSE T2 template  \n",
    "- Atlas anatomical labels\n",
    "\n",
    "**Output Files:**\n",
    "- Registered atlas images at each stage\n",
    "- Transformation files\n",
    "- Quality metrics (Jacobian determinants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load original reoriented image and resample to 0.1mm cubic voxels, preserving FOV using nibabel\n",
    "dir_name = '/project2/ajoshi_1183/data'\n",
    "if not os.path.isdir(dir_name):\n",
    "    dir_name = '/home/ajoshi/project2_ajoshi_1183/data'\n",
    "\n",
    "fname = f\"{dir_name}/RodentTools/for_Seymour/11_15_2025/MRI/Raw T2/r59/r59.r.nii.gz\"\n",
    "subbase=f\"{dir_name}/RodentTools/for_Seymour/11_15_2025/MRI/Raw T2/r59/R59\"\n",
    "\n",
    "if not os.path.isfile(subbase + \".reoriented.nii.gz\"):\n",
    "    img = nb.load(fname)\n",
    "    resampled_img = resample_to_output(img, voxel_sizes=(0.1, 0.1, 0.1), order=1)  # order=1: linear interpolation\n",
    "    nb.save(resampled_img, subbase + \".reoriented.nii.gz\")\n",
    "\n",
    "#subbase = f\"{dir_name}/RodentTools/data/test4/29408.native\"#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run BrainSuite's BSE and interactive mask tool to generate brain mask and skull stripped image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sub_bse_t2 = f\"{dir_name}/RodentTools/for_Seymour/11_15_2025/MRI/Raw T2/r59/R59.reoriented.bse.nii.gz\" #subbase+\".bfc.nii.gz\"\n",
    "\n",
    "# Run BrainSuite BSE to get brain-extracted image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "atlas_bse_t2 = f\"{dir_name}/RodentTools/Atlases/Waxholm/WHS_SD_rat_atlas_v4_pack/WHS_SD_rat_T2star_v1.01.bse.nii.gz\"\n",
    "atlas_labels = f\"{dir_name}/RodentTools/Atlases/Waxholm/WHS_SD_rat_atlas_v4_pack/WHS_SD_rat_atlas_v4.nii.gz\"\n",
    "\n",
    "centered_atlas = subbase+\".atlas.cent.nii.gz\"\n",
    "centered_atlas_labels = subbase+\".atlas.cent.label.nii.gz\"\n",
    "cent_transform_file = subbase+\".cent.reg.tfm\"\n",
    "inv_cent_transform_file = subbase+\".cent.reg.inv.tfm\"\n",
    "centered_atlas_linreg = subbase+\".atlas.lin.nii.gz\"\n",
    "centered_atlas_linreg_labels = subbase+\".atlas.lin.label.nii.gz\"\n",
    "lin_reg_map_file = subbase+\".lin_ddf.map.nii.gz\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Brain Mask for Damaged Tissue\n",
    "\n",
    "**Critical for ex vivo brains with cuts/artifacts!**\n",
    "\n",
    "This mask tells the registration algorithm which regions to use for alignment. Areas outside the mask are ignored, preventing the algorithm from trying to match damaged/cut regions.\n",
    "\n",
    "Two approaches:\n",
    "1. **Automatic** (quick): Threshold-based masking (run the cell below)\n",
    "2. **Manual** (better): Create/edit mask in ITK-SNAP or BrainSuite for precise control over excluded regions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or load brain mask to exclude damaged regions\n",
    "# --- Method 1: Atlas-Guided Masking (More Robust) ---\n",
    "\n",
    "# Step 1: Warp the atlas brain mask to the subject space using the affine transform\n",
    "print(\"Warping atlas mask to subject space...\")\n",
    "\n",
    "# Create a mask from the atlas BSE image if it doesn't exist\n",
    "atlas_mask_file = atlas_bse_t2.replace('.nii.gz', '.mask.nii.gz') \n",
    "if not os.path.isfile(atlas_mask_file):\n",
    "    print(\"Atlas mask not found, creating one from BSE image...\")\n",
    "    atlas_img = nb.load(atlas_bse_t2)\n",
    "    atlas_data = atlas_img.get_fdata()\n",
    "    atlas_mask_data = (atlas_data > np.percentile(atlas_data[atlas_data>0], 5)).astype(np.uint8)\n",
    "    atlas_mask_img = nb.Nifti1Image(atlas_mask_data, atlas_img.affine, atlas_img.header)\n",
    "    nb.save(atlas_mask_img, atlas_mask_file)\n",
    "\n",
    "# We need to apply the rigid and affine transforms to the atlas mask\n",
    "# First, apply the centering (rigid) transform\n",
    "centered_atlas_mask_file = subbase + \".atlas.cent.mask.nii.gz\"\n",
    "moving_mask = sitk.ReadImage(atlas_mask_file, sitk.sitkUInt8)\n",
    "fixed_image = sitk.ReadImage(sub_bse_t2, sitk.sitkFloat32)\n",
    "final_transform = sitk.ReadTransform(cent_transform_file)\n",
    "moved_mask = sitk.Resample(moving_mask, fixed_image, final_transform, sitk.sitkNearestNeighbor)\n",
    "sitk.WriteImage(moved_mask, centered_atlas_mask_file)\n",
    "\n",
    "# Then, apply the affine transform using the displacement field\n",
    "aff_disp_field, _ = LoadImage(image_only=False)(lin_reg_map_file)\n",
    "aff_disp_field = EnsureChannelFirst()(aff_disp_field)\n",
    "centered_mask, _ = LoadImage(image_only=False)(centered_atlas_mask_file)\n",
    "centered_mask = EnsureChannelFirst()(centered_mask)\n",
    "warped_atlas_mask = apply_warp(aff_disp_field[None,], centered_mask[None,], centered_mask[None,], interp_mode=\"nearest\")\n",
    "warped_atlas_mask_data = warped_atlas_mask[0, 0].detach().cpu().numpy()\n",
    "\n",
    "# Step 2: Create an intensity-based mask from the subject image\n",
    "print(\"Creating intensity mask from subject...\")\n",
    "sub_img = nb.load(sub_bse_t2)\n",
    "sub_data = sub_img.get_fdata()\n",
    "intensity_mask = (sub_data > np.percentile(sub_data[sub_data > 0], 5)).astype(np.uint8)\n",
    "\n",
    "# Step 3: Combine the masks (intersection) and clean up\n",
    "print(\"Combining masks and cleaning up...\")\n",
    "combined_mask = (warped_atlas_mask_data * intensity_mask).astype(np.uint8)\n",
    "\n",
    "from scipy import ndimage\n",
    "combined_mask = ndimage.binary_fill_holes(combined_mask)\n",
    "combined_mask = ndimage.binary_opening(combined_mask, iterations=2) # Opening removes small bright spots\n",
    "combined_mask = ndimage.binary_dilation(combined_mask, iterations=3) # Dilate to recover boundary\n",
    "\n",
    "# Step 4: Save and visualize the final mask\n",
    "mask_img = nb.Nifti1Image(combined_mask, sub_img.affine, sub_img.header)\n",
    "target_mask_file = subbase + \".atlas_guided_mask.nii.gz\"\n",
    "nb.save(mask_img, target_mask_file)\n",
    "print(f\"Atlas-guided brain mask saved to: {target_mask_file}\")\n",
    "\n",
    "# Visualize the final mask\n",
    "plot_anat(sub_bse_t2, vmax=np.percentile(sub_data, 99.9), vmin=0, title=\"Subject with Atlas-Guided Mask Overlay\")\n",
    "d = plot_anat(sub_bse_t2, vmax=np.percentile(sub_data, 99.9), vmin=0)\n",
    "d.add_contours(target_mask_file, levels=[0.5], colors='g') # Green for the new mask\n",
    "\n",
    "# --- Method 2 (RECOMMENDED FOR PRECISION): Manually create/edit mask in ITK-SNAP or BrainSuite ---\n",
    "# Then load it here:\n",
    "# target_mask_file = subbase + \".manual_mask.nii.gz\"  # Your manually created mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nonlin_reg_map_file = subbase+\".nonlin_ddf.map.nii.gz\"\n",
    "inv_nonlin_reg_map_file = subbase+\".inv.nonlin_ddf.map.nii.gz\"\n",
    "centered_atlas_nonlinreg = subbase+\".atlas.nonlin.nii.gz\"\n",
    "centered_atlas_nonlinreg_labels = subbase+\".atlas.nonlin.label.nii.gz\"\n",
    "jac_det_file = subbase+\".jacobian_det.nii.gz\"\n",
    "inv_jac_det_file = subbase+\".inv.jacobian_det.nii.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initial Data Visualization\n",
    "\n",
    "Visualize the input data before registration to understand the initial alignment between subject and atlas images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_anat(sub_bse_t2)\n",
    "d = plot_anat(atlas_bse_t2)\n",
    "d.add_contours(atlas_labels, cmap=\"prism\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=plot_anat(sub_bse_t2, vmax=np.percentile(nb.load(sub_bse_t2).get_fdata(), 99.9),vmin=0)\n",
    "d.add_contours(atlas_labels, cmap=\"prism\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Rigid Registration (Center Alignment)\n",
    "\n",
    "Perform initial rigid registration to align the center of mass between the atlas and subject images. This step corrects for gross positioning differences and provides a good starting point for subsequent registrations.\n",
    "\n",
    "**Key Steps:**\n",
    "1. Initialize centered transform using geometry\n",
    "2. Perform multi-resolution registration\n",
    "3. Save forward and inverse transformations\n",
    "4. Apply transformation to atlas and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_image = sitk.ReadImage(sub_bse_t2, sitk.sitkFloat32)\n",
    "moving_image = sitk.ReadImage(atlas_bse_t2, sitk.sitkFloat32)\n",
    "initial_transform = sitk.CenteredTransformInitializer(\n",
    "    fixed_image,\n",
    "    moving_image,\n",
    "    sitk.Euler3DTransform(),\n",
    "    sitk.CenteredTransformInitializerFilter.GEOMETRY,\n",
    ")\n",
    "\n",
    "final_transform, _ = multires_registration(\n",
    "    fixed_image, moving_image, initial_transform)\n",
    "\n",
    "\n",
    "# save the transformation in a file\n",
    "sitk.WriteTransform(final_transform, cent_transform_file)\n",
    "\n",
    "# invert the transform and also save to a file\n",
    "inv_transform = final_transform.GetInverse()\n",
    "sitk.WriteTransform(inv_transform, inv_cent_transform_file)\n",
    "\n",
    "# load from the file and apply the transformation\n",
    "final_transform = sitk.ReadTransform(cent_transform_file)\n",
    "moved_image = sitk.Resample(moving_image, fixed_image, final_transform)\n",
    "\n",
    "sitk.WriteImage(moved_image, centered_atlas)\n",
    "\n",
    "moving_image = sitk.ReadImage(atlas_labels, sitk.sitkUInt16)\n",
    "moved_image = sitk.Resample(\n",
    "    moving_image,\n",
    "    fixed_image,\n",
    "    transform=final_transform,\n",
    "    interpolator=sitk.sitkNearestNeighbor,\n",
    ")\n",
    "sitk.WriteImage(moved_image, centered_atlas_labels)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Visualize Rigid Registration Results\n",
    "\n",
    "Check the quality of the rigid registration by overlaying the centered atlas with the subject image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_anat(centered_atlas)\n",
    "d=plot_anat(sub_bse_t2, vmax=np.percentile(nb.load(sub_bse_t2).get_fdata(), 99.9),vmin=0)\n",
    "d.add_contours(centered_atlas_labels, cmap=\"prism\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Affine Registration\n",
    "\n",
    "Perform affine (linear) registration to account for scaling, rotation, and shearing differences between the atlas and subject. This builds upon the rigid registration to provide better anatomical alignment.\n",
    "\n",
    "**Parameters:**\n",
    "- **Loss function:** Cross-correlation (CC)\n",
    "- **Transformation type:** Affine (12 degrees of freedom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligner = Aligner()\n",
    "aligner.affine_reg(\n",
    "    fixed_file=sub_bse_t2,\n",
    "    moving_file=centered_atlas,\n",
    "    output_file=centered_atlas_linreg,\n",
    "    ddf_file=lin_reg_map_file,\n",
    "    loss=\"mse\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Apply Affine Transform to Labels\n",
    "\n",
    "Apply the computed affine transformation to the atlas labels using the displacement field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=plot_anat(sub_bse_t2, vmax=np.percentile(nb.load(sub_bse_t2).get_fdata(), 99.9),vmin=0)\n",
    "d.add_contours(centered_atlas_linreg, cmap=\"prism\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_field, meta = LoadImage(image_only=False)(lin_reg_map_file)\n",
    "disp_field = EnsureChannelFirst()(disp_field)\n",
    "print(disp_field.shape)\n",
    "\n",
    "at1, meta = LoadImage(image_only=False)(centered_atlas_labels)\n",
    "at_lab = EnsureChannelFirst()(at1)\n",
    "print(at_lab.shape)\n",
    "\n",
    "warped_lab = apply_warp(\n",
    "    disp_field[None,], at_lab[None,], at_lab[None,], interp_mode=\"nearest\"\n",
    ")\n",
    "nb.save(\n",
    "    nb.Nifti1Image(warped_lab[0, 0].detach().cpu().numpy(), at_lab.affine),\n",
    "    centered_atlas_linreg_labels,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Compare Registration Results\n",
    "\n",
    "Visual comparison between rigid and affine registration results to assess improvement in anatomical alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = plot_anat(sub_bse_t2, vmax=np.percentile(nb.load(sub_bse_t2).get_fdata(), 99),vmin=0)\n",
    "d.add_contours(centered_atlas_labels, cmap=\"prism\")\n",
    "d = plot_anat(sub_bse_t2, vmax=np.percentile(nb.load(sub_bse_t2).get_fdata(), 99.95),vmin=np.percentile(nb.load(sub_bse_t2).get_fdata(), 15))\n",
    "d.add_contours(centered_atlas_linreg_labels, cmap=\"hsv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Non-linear Registration\n",
    "\n",
    "Perform deformable (non-linear) registration to capture local anatomical variations that cannot be corrected by linear transformations alone. This step uses a neural network-based approach for precise anatomical matching.\n",
    "\n",
    "**Parameters optimized for ex vivo brains with artifacts:**\n",
    "- **Network input size:** 96×96×96 (increased from 64 for better resolution)\n",
    "- **Learning rate:** 5e-5 (decreased for stability with damaged tissue)\n",
    "- **Maximum epochs:** 7500 (increased for better convergence)\n",
    "- **Loss function:** Cross-correlation (CC) - robust to intensity variations\n",
    "- **Regularization penalty:** 2.0 (increased to prevent overfitting to artifacts)\n",
    "\n",
    "**Note:** For ex vivo brains with cuts or damage, consider:\n",
    "1. Creating a brain mask to exclude damaged regions\n",
    "2. Using the `target_mask` parameter to focus registration on intact tissue\n",
    "3. Increasing regularization (reg_penalty) to prevent unrealistic deformations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips for Improving Registration Quality with Damaged Ex Vivo Brains\n",
    "\n",
    "**Common Issues with Ex Vivo Tissue:**\n",
    "- Cuts, tears, or missing tissue sections\n",
    "- Uneven fixation causing local distortions\n",
    "- Artifacts from sectioning or handling\n",
    "- Different contrast properties vs in vivo imaging\n",
    "\n",
    "**Strategies to Improve Results:**\n",
    "\n",
    "1. **Masking** (most important): Create a binary mask excluding damaged regions\n",
    "   - Use `target_mask` parameter in `nonlinear_reg()`\n",
    "   - Mask out cuts, tears, and artifact regions\n",
    "   - Focus registration only on intact tissue\n",
    "\n",
    "2. **Regularization**: Increase `reg_penalty` (1.5-3.0)\n",
    "   - Prevents unrealistic deformations at artifact boundaries\n",
    "   - Smooths out registration in problematic areas\n",
    "   - Higher values = smoother, more constrained deformations\n",
    "\n",
    "3. **Network Resolution**: Increase `nn_input_size` (96 or 128)\n",
    "   - Better captures fine anatomical details\n",
    "   - May require more GPU memory\n",
    "   - Generally improves results for high-res images\n",
    "\n",
    "4. **Learning Rate**: Decrease `lr` (1e-5 to 5e-5)\n",
    "   - More stable convergence with noisy/damaged data\n",
    "   - Prevents overshooting during optimization\n",
    "   - May need more epochs to converge\n",
    "\n",
    "5. **Training Duration**: Increase `max_epochs` (7500-10000)\n",
    "   - Allows more time for convergence\n",
    "   - Monitor loss to ensure convergence (should plateau)\n",
    "   - Use early stopping if loss stops improving\n",
    "\n",
    "6. **Loss Function**: Keep `loss=\"cc\"` (cross-correlation)\n",
    "   - Most robust for intensity variations in ex vivo\n",
    "   - Alternative: Try `loss=\"mi\"` (mutual information) for severe artifacts\n",
    "\n",
    "7. **Pre-processing**: Improve affine registration first\n",
    "   - Ensure good initial alignment before non-linear\n",
    "   - Consider increasing affine max_epochs\n",
    "   - Check rigid registration quality visually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlin_reg = Warper()\n",
    "nonlin_reg.nonlinear_reg(\n",
    "    target_file=sub_bse_t2,\n",
    "    moving_file=centered_atlas_linreg,\n",
    "    output_file=centered_atlas_nonlinreg,\n",
    "    target_mask=target_mask_file,  # Use MASK to exclude damaged regions\n",
    "    ddf_file=nonlin_reg_map_file,\n",
    "    inv_ddf_file=inv_nonlin_reg_map_file,\n",
    "    reg_penalty=2.0,  # INCREASED: More regularization for damaged tissue\n",
    "    nn_input_size=96,  # INCREASED: Better resolution for fine details\n",
    "    lr=5e-5,  # DECREASED: More stable convergence\n",
    "    max_epochs=7500,  # INCREASED: More iterations for convergence\n",
    "    loss=\"cc\",\n",
    "    jacobian_determinant_file=jac_det_file,\n",
    "    inv_jacobian_determinant_file=inv_jac_det_file,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Apply Non-linear Transformation\n",
    "\n",
    "Apply the computed deformation field to transform the atlas labels to match the subject anatomy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_field, meta = LoadImage(image_only=False)(nonlin_reg_map_file)\n",
    "disp_field = EnsureChannelFirst()(disp_field)\n",
    "print(disp_field.shape)\n",
    "\n",
    "at1, meta = LoadImage(image_only=False)(centered_atlas_linreg_labels)\n",
    "at_lab = EnsureChannelFirst()(at1)\n",
    "print(at_lab.shape)\n",
    "\n",
    "warped_lab = apply_warp(\n",
    "    disp_field[None,], at_lab[None,], at_lab[None,], interp_mode=\"nearest\"\n",
    ")\n",
    "nb.save(\n",
    "    nb.Nifti1Image(\n",
    "        np.uint16(warped_lab[0, 0].detach().cpu().numpy()), at_lab.affine),\n",
    "    centered_atlas_nonlinreg_labels,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Compare Registration Stages\n",
    "\n",
    "Visual comparison between affine and non-linear registration results to evaluate the improvement in anatomical detail matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = plot_anat(sub_bse_t2, vmax=np.percentile(nb.load(sub_bse_t2).get_fdata(), 99),vmin=0)\n",
    "d.add_contours(centered_atlas_linreg_labels, cmap=\"prism\")\n",
    "d = plot_anat(sub_bse_t2, vmax=np.percentile(nb.load(sub_bse_t2).get_fdata(), 99),vmin=0)\n",
    "d.add_contours(centered_atlas_nonlinreg_labels, cmap=\"prism\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Registration Quality Assessment\n",
    "\n",
    "Evaluate the quality of the non-linear registration using Jacobian determinant analysis. The Jacobian determinant measures local volume changes and helps identify areas of expansion/compression in the deformation field.\n",
    "\n",
    "**Interpretation:**\n",
    "- **Jacobian = 1:** No volume change (perfect preservation)\n",
    "- **Jacobian > 1:** Local expansion \n",
    "- **Jacobian < 1:** Local compression\n",
    "- **Values close to 0:** Potential registration artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_anat(jac_det_file, colorbar=True)\n",
    "\n",
    "jac=nb.load(jac_det_file)\n",
    "jac = jac.get_fdata() - 1\n",
    "\n",
    "from nilearn.image import new_img_like\n",
    "jac = new_img_like(sub_bse_t2,jac)\n",
    "plot_stat_map(jac,sub_bse_t2,title='Jac det')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Forward Jacobian Determinant\n",
    "\n",
    "Analysis of the forward transformation (atlas → subject) Jacobian determinant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_anat(inv_jac_det_file, colorbar=True)\n",
    "\n",
    "jac=nb.load(inv_jac_det_file)\n",
    "jac = jac.get_fdata() - 1\n",
    "\n",
    "from nilearn.image import new_img_like\n",
    "jac = new_img_like(sub_bse_t2,jac)\n",
    "plot_stat_map(jac,sub_bse_t2,title='Jac det inv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Inverse Jacobian Determinant  \n",
    "\n",
    "Analysis of the inverse transformation (subject → atlas) Jacobian determinant to assess bidirectional registration quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Electrode Deformation Analysis\n",
    "\n",
    "This section demonstrates specialized electrode deformation modeling, which is crucial for understanding how brain tissue deforms around implanted electrodes. This analysis helps in:\n",
    "\n",
    "- **Correcting registration artifacts** caused by electrode implantation\n",
    "- **Modeling tissue displacement** around foreign objects\n",
    "- **Improving anatomical accuracy** in regions affected by electrodes\n",
    "\n",
    "The deformation modeling uses specific target points that represent the electrode center and tip positions, allowing for precise modeling of the cylindrical deformation field around the electrode tract.\n",
    "\n",
    "### Key Parameters:\n",
    "- **Target points:** Coordinates defining electrode center and tip\n",
    "- **Deformation model:** Cylindrical field around electrode tract  \n",
    "- **Label handling:** Nearest-neighbor interpolation for discrete labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules for electrode deformation\n",
    "from deform_image_by_electrode import deform_image_by_electrode\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 First Electrode Deformation\n",
    "\n",
    "Model deformation around the first electrode using the linearly registered atlas as the starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First electrode deformation example\n",
    "# Define paths for the first electrode\n",
    "target_path = subbase + \".atlas.lin.label.nii.gz\"\n",
    "target_electrode_path = subbase + \".atlas.lin.electrode1.label.nii.gz\"\n",
    "target_electrode_deformed_path = subbase + \".atlas.lin.electrode1.deformed.label.nii.gz\"\n",
    "target_electrode_deformed_path = subbase + \".reoriented.atlas.lin.electrode1.deformed.label.nii.gz\"\n",
    "\n",
    "# Define target points for first electrode (center and tip)\n",
    "target_pts = [[-2.08, -1.74, 6.86], [-2.18, -3.12, -0.54]]\n",
    "\n",
    "# Perform electrode deformation\n",
    "deform_image_by_electrode(\n",
    "    target_path=target_path,\n",
    "    target_electrode_path=target_electrode_path,\n",
    "    target_electrode_deformed_path=target_electrode_deformed_path,\n",
    "    target_pts=target_pts, \n",
    "    islabel=True  # mark center of electrode and tip of electrode\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Second Electrode Deformation\n",
    "\n",
    "Model deformation around the second electrode using the result from the first electrode deformation. This sequential approach accounts for the cumulative effects of multiple electrode insertions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second electrode deformation example\n",
    "# Define paths for the second electrode (using first electrode's deformed result as input)\n",
    "target_path = subbase + \".reoriented.atlas.lin.electrode1.deformed.label.nii.gz\"\n",
    "target_electrode_path = subbase + \".reoriented.atlas.lin.electrode2.label.nii.gz\"\n",
    "target_electrode_deformed_path = subbase + \".reoriented.atlas.lin.electrode2.deformed.label.nii.gz\"\n",
    "\n",
    "# Define target points for second electrode (center and tip)\n",
    "target_pts = [[-4.00, -5.72, 6.86], [-4.70, -6.62, -0.40]]\n",
    "\n",
    "# Perform electrode deformation\n",
    "deform_image_by_electrode(\n",
    "    target_path=target_path,\n",
    "    target_electrode_path=target_electrode_path,\n",
    "    target_electrode_deformed_path=target_electrode_deformed_path,\n",
    "    target_pts=target_pts, \n",
    "    islabel=True  # mark center of electrode and tip of electrode\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated a complete pipeline for rodent brain atlas registration and electrode deformation analysis:\n",
    "\n",
    "### Registration Pipeline:\n",
    "1. **Rigid Registration** - Initial center alignment\n",
    "2. **Affine Registration** - Linear transformation refinement  \n",
    "3. **Non-linear Registration** - Deformable registration for precise anatomical matching\n",
    "4. **Quality Assessment** - Jacobian determinant analysis\n",
    "\n",
    "### Electrode Deformation Modeling:\n",
    "- Specialized deformation field modeling around electrode tracts\n",
    "- Sequential processing for multiple electrodes\n",
    "- Tissue displacement correction for improved registration accuracy\n",
    "\n",
    "### Key Outputs:\n",
    "- Registered atlas images at each transformation stage\n",
    "- Anatomical labels aligned to subject space\n",
    "- Quality metrics (Jacobian determinants)\n",
    "- Electrode deformation-corrected registrations\n",
    "\n",
    "### Applications:\n",
    "- Accurate anatomical labeling of rodent brain regions\n",
    "- Quantification of tissue deformation due to electrode implantation  \n",
    "- Quality control for registration accuracy\n",
    "- Research in neuroscience and medical imaging\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** File paths in this notebook are configured for a specific dataset (R57). Update the file paths in section 2 to match your data organization before running the pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
